# ğŸŒ¡ï¸ GenHack4 â€“ Climate Heat Downscaling Pipeline

[![Cloud Run](https://img.shields.io/badge/Cloud%20Run-Deployed-blue)](https://console.cloud.google.com/run/jobs?project=genhack-heat-dev)  
**Phase 1**: Mock data pipeline with complete infrastructure and contracts.  

[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://console.cloud.google.com/artifacts/docker/genhack-heat-dev/europe/heat)  
**Phase 2+**: Real ERA5/Sentinel-2 data + U-Net/SRGAN models.

[![Python](https://img.shields.io/badge/Python-3.11-blue)](https://www.python.org/)

---

> Pipeline de downscaling climatique pour la dÃ©tection et lâ€™analyse des Ã®lots de chaleur urbains avec donnÃ©es mock (Phase 1).

---

## ğŸ¯ Objectif

SystÃ¨me de traitement gÃ©ospatial automatisÃ© pour :

- IngÃ©rer des donnÃ©es climatiques (tempÃ©rature, humiditÃ©, vent)
- Calculer des indices spectraux (NDVI, NDBI)
- GÃ©nÃ©rer des indicateurs de chaleur (intensitÃ©, durÃ©e, Ã©tendue, UHI)
- Produire des rapports HTML/PDF avec cartes et statistiques
- Exporter des GeoTIFF Cloud Optimized

---

## ğŸš€ Quick Start (< 2 minutes)

```bash
# 1. Initialize infrastructure (check Phase 0 setup)
make init

# 2. Build Docker image
make build

# 3. Deploy to Cloud Run
make deploy

# 4. Execute pipeline
make run

# 5. View outputs
gsutil ls gs://gh-exports-genhack-heat-dev/paris/2022/
```

Output: GeoTIFF temperature maps + NDVI/NDBI indices + HTML/PDF report

â¸»

ğŸ“‹ Project Structure
```
genhack-heat/
â”œâ”€â”€ src/                 # Pipeline modules
â”‚   â”œâ”€â”€ models.py        # Pydantic data models
â”‚   â”œâ”€â”€ ingest.py        # Data ingestion (Phase 1: mock)
â”‚   â”œâ”€â”€ preprocess.py    # Reprojection & resampling
â”‚   â”œâ”€â”€ features.py      # Spectral indices (NDVI, NDBI)
â”‚   â”œâ”€â”€ train.py         # Model training (Phase 2+)
â”‚   â”œâ”€â”€ evaluate.py      # Metrics computation
â”‚   â”œâ”€â”€ indicators.py    # Heat indicators
â”‚   â”œâ”€â”€ publish.py       # GeoTIFF export
â”‚   â””â”€â”€ report.py        # HTML/PDF generation
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ job_main.py      # Orchestrator
â”‚   â”œâ”€â”€ Dockerfile.geo   # GDAL + geospatial stack
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ paris_2022_mock.yml  # Pipeline configuration
â”‚
â”œâ”€â”€ schemas/             # JSON schemas for contracts
â”œâ”€â”€ templates/           # Jinja2 report templates
â”œâ”€â”€ tests/               # Contract validation tests
â”œâ”€â”€ infra/               # Deployment scripts
â”‚   â”œâ”€â”€ init-genhack.sh
â”‚   â””â”€â”€ deploy_job.sh
â”œâ”€â”€ .github/workflows/   # CI/CD
â”‚   â””â”€â”€ build_deploy.yml
â””â”€â”€ Makefile             # Development commands
```

â¸»

ğŸ”§ Requirements
	â€¢	GCP Project: genhack-heat-dev (Phase 0 setup complete)
	â€¢	Docker: For local builds
	â€¢	gcloud CLI: For deployment
	â€¢	Python 3.11+: For local testing

â¸»

ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloud Run Job  â”‚
â”‚  (genhack-heat) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Docker  â”‚
    â”‚ Image   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Pipeline (8 stages)                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  1. Ingest    â†’ Mock data           â”‚
    â”‚  2. Preprocess â†’ Reprojection       â”‚
    â”‚  3. Features  â†’ NDVI/NDBI           â”‚
    â”‚  4. Train     â†’ (Phase 2)           â”‚
    â”‚  5. Evaluate  â†’ Metrics             â”‚
    â”‚  6. Indicators â†’ Heat stats         â”‚
    â”‚  7. Publish   â†’ GeoTIFF/PNG         â”‚
    â”‚  8. Report    â†’ HTML/PDF            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â¸»

ğŸ“Š Pipeline Stages
	1.	Ingest â†’ Generate/download climate data
	2.	Preprocess â†’ Reproject to target CRS
	3.	Features â†’ Compute NDVI, NDBI indices
	4.	Train â†’ Model training (Phase 2+)
	5.	Evaluate â†’ Compute metrics
	6.	Indicators â†’ Heat intensity, UHI, extent
	7.	Publish â†’ Export GeoTIFF + PNG previews
	8.	Report â†’ Generate HTML/PDF

â¸»

ğŸ› ï¸ Technologies

Stack GÃ©ospatial
	â€¢	GDAL 3.x â€“ Manipulation rasters
	â€¢	PROJ 9.x â€“ Transformations coordonnÃ©es
	â€¢	rasterio â€“ I/O rasters Python
	â€¢	xarray â€“ Arrays multidimensionnels
	â€¢	geopandas â€“ DonnÃ©es vectorielles

Reporting
	â€¢	Jinja2 â€“ Templates HTML
	â€¢	Weasyprint â€“ GÃ©nÃ©ration PDF
	â€¢	matplotlib â€“ Visualisations

â¸»

ğŸ“ Data Contracts

All stages communicate via validated JSON schemas:
	â€¢	Manifest: City, period, grid, variables
	â€¢	RasterMetadata: CRS, transform, bounds, dtype
	â€¢	Metrics: RMSE, MAE, RÂ², baseline comparison
	â€¢	Indicators: Heat intensity, duration, extent, UHI

Run tests:
```bash
make test
pytest tests/test_contracts.py -v
```

â¸»

ğŸ“Š Outputs

La pipeline gÃ©nÃ¨re :
	â€¢	GeoTIFF : Rasters temperature, NDVI, NDBI (Cloud Optimized)
	â€¢	PNG : PrÃ©visualisations avec cartes de chaleur
	â€¢	JSON : Indicateurs, mÃ©triques, mÃ©tadonnÃ©es
	â€¢	HTML/PDF : Rapports complets avec visualisations

â¸»

ğŸ”’ Security & Isolation

âœ… Clean-room duplication from Kura project
âœ… Separate GCP project (genhack-heat-dev)
âœ… No shared resources (buckets, SAs, KMS)
âœ… CI/CD checks block any Kura references

â¸»

ğŸ§ª Tests

# Tests de validation des schemas
make test

# VÃ©rification de l'infrastructure
bash infra/init-genhack.sh

Phase 1 Complete â†’ Ready for Phase 2 (real data ingestion)

â¸»

ğŸ“ˆ MÃ©triques Pipeline
	â€¢	â±ï¸ Temps dâ€™exÃ©cution : 2.4s (Phase 1 mock)
	â€¢	ğŸ’¾ Taille image : ~2.0 GB
	â€¢	ğŸ”„ Build time : ~2 min (premiÃ¨re fois), ~5s (cache)

â¸»

ğŸŒ Configuration
```
city: "paris"
period:
  start: "2022-07-15"
  end: "2022-07-17"
grid:
  crs: "EPSG:3857"
  resolution_m: 200
variables: ["t2m", "tx", "tn", "rh"]
mode:
  dry_run: true  # Phase 1: mock data
```

â¸»

ğŸš¦ Statut

Composant	Statut
Infrastructure (Phase 0)	âœ… Complet
Pipeline Mock (Phase 1)	âœ… DÃ©ployÃ©
Cloud Run Job	âœ… Actif
Docker Image	âœ… PubliÃ©
CI/CD	âœ… ConfigurÃ©
Phase 2 (donnÃ©es rÃ©elles)	ğŸ”œ Ã€ venir


â¸»

ğŸ¯ Roadmap Phase 2
	â€¢	Ingestion ERA5 (Copernicus CDS API)
	â€¢	IntÃ©gration Sentinel-2 (Google Earth Engine)
	â€¢	Extraction features OSM
	â€¢	ModÃ¨le U-Net pour downscaling
	â€¢	Upload outputs vers GCS
	â€¢	API REST

â¸»

ğŸ“š Documentation
	â€¢	ARCHITECTURE.mdï¿¼ â€“ System design
	â€¢	SCHEMAS.mdï¿¼ â€“ Data contracts
	â€¢	REPRODUCE.mdï¿¼ â€“ Step-by-step reproduction

â¸»

ğŸ” SÃ©curitÃ©
	â€¢	âœ… Isolation complÃ¨te : Projet GCP dÃ©diÃ© (genhack-heat-dev)
	â€¢	âœ… CMEK : Chiffrement avec Cloud KMS
	â€¢	âœ… Service Account : Permissions minimales
	â€¢	âœ… CI/CD : VÃ©rification sÃ©curitÃ© automatique

â¸»

ğŸ¤ Contributing

This is a hackathon project for GenHack 2025 (climate track).
Clean-room duplication from Kura mental health project.

License: Apache 2.0
Author: Robin QuÃ©riaux
Contact: queriauxrobin@gmail.com

DerniÃ¨re mise Ã  jour : 8 novembre 2025
Version Pipeline : 1.0.0 (Phase 1 - Mock Data)

â¸»

ğŸ¯ Next Steps (Phase 2)
	1.	Real ERA5 data ingestion via Copernicus API
	2.	Sentinel-2 imagery download from Google Earth Engine
	3.	U-Net model training for downscaling
	4.	Multi-city heat analysis
	5.	Population exposure estimates

See: GENHACK_CLEAN_ROOM_DUPLICATION.md for full roadmap
