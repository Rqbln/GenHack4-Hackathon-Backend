# ğŸ—ï¸ Architecture - GenHack Climate Heat Downscaling

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLOUD RUN JOB ORCHESTRATOR                  â”‚
â”‚                      (pipeline/job_main.py)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                    â”‚
             â–¼                                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   GCS BUCKETS      â”‚              â”‚  ARTIFACT REGISTRY â”‚
    â”‚  (CMEK encrypted)  â”‚              â”‚   (Docker images)  â”‚
    â”‚                    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ â€¢ gh-raw-*         â”‚
    â”‚ â€¢ gh-intermediate-*â”‚
    â”‚ â€¢ gh-models-*      â”‚
    â”‚ â€¢ gh-exports-*     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pipeline Stages

### 1. **Ingest** (`src/ingest.py`)

**Purpose**: Acquire climate and satellite data

**Phase 1 (Mock)**:
- Generates synthetic rasters (128Ã—128) with spatial patterns
- Temperature: urban heat island effect (warmer center)
- Variables: t2m, tx, tn, rh, u10, v10

**Phase 2+ (Real)**:
- ERA5: Download from Copernicus Climate Data Store
- Sentinel-2: Query Google Earth Engine API
- OSM: Extract features via Overpass API

**Output**: Raw GeoTIFF files + `manifest.json`

---

### 2. **Preprocess** (`src/preprocess.py`)

**Purpose**: Spatial harmonization

**Operations**:
- Reproject to target CRS (EPSG:3857 or EPSG:2154)
- Resample to common resolution (200m)
- Apply bilinear/bicubic interpolation

**Output**: Reprojected rasters + `raster_metadata.json`

---

### 3. **Features** (`src/features.py`)

**Purpose**: Compute spectral indices from satellite imagery

**Indices**:
- **NDVI**: `(NIR - Red) / (NIR + Red)` - vegetation
- **NDBI**: `(SWIR - NIR) / (SWIR + NIR)` - built-up areas

**Phase 1**: Mock indices with inverse temp relationship  
**Phase 2+**: Real S2 bands (B2, B3, B4, B8, B11, B12)

**Output**: Feature rasters + metadata

---

### 4. **Train** (`src/train.py`)

**Purpose**: Model training for downscaling

**Phase 1**: No-op (placeholder)

**Phase 2+**:
- U-Net architecture (encoder-decoder)
- Input: Low-res ERA5 (25km) + features (NDVI, NDBI, elevation)
- Output: High-res temperature (100-200m)
- Loss: MSE + perceptual loss
- Training: 80/20 train/val split

---

### 5. **Evaluate** (`src/evaluate.py`)

**Purpose**: Quantitative model assessment

**Metrics**:
- RMSE (Root Mean Square Error)
- MAE (Mean Absolute Error)
- RÂ² (coefficient of determination)
- Bias (mean predicted - observed)

**Baseline**: Bicubic upsampling for comparison

**Phase 1**: Placeholder (nulls)  
**Phase 2+**: Real validation against ground truth

---

### 6. **Indicators** (`src/indicators.py`)

**Purpose**: Climate impact indicators

**Computed**:
- Heat intensity (Â°C above threshold)
- Duration (days above 30Â°C)
- Spatial extent (kmÂ²)
- Urban heat island intensity (urban - rural)
- Percentiles (95th, 99th)

**Use Case**: Urban planning, public health alerts

---

### 7. **Publish** (`src/publish.py`)

**Purpose**: Export final outputs

**Formats**:
- **GeoTIFF**: Cloud Optimized (COG) with LZW compression
- **PNG**: Preview images with colormaps
- **JSON**: Metadata for downstream tools

**Output Structure**:
```
gs://gh-exports-genhack-heat-dev/
â””â”€â”€ paris/
    â””â”€â”€ 2022/
        â”œâ”€â”€ paris_temperature.tif
        â”œâ”€â”€ paris_temperature.png
        â”œâ”€â”€ paris_ndvi.tif
        â”œâ”€â”€ paris_ndbi.tif
        â””â”€â”€ export_metadata.json
```

---

### 8. **Report** (`src/report.py`)

**Purpose**: Human-readable summaries

**Features**:
- Jinja2 templating (HTML)
- Weasyprint conversion (PDF)
- Embedded maps (PNG previews)
- Metrics tables
- Indicator visualizations

**Output**: `paris_report.html` + `paris_report.pdf`

---

## Data Flow

```
CONFIG (YAML)
     â”‚
     â–¼
 MANIFEST (init)
     â”‚
     â”œâ”€â†’ INGEST â”€â”€â”€â”€â”€â”€â†’ Raw GeoTIFFs â”€â”€â”€â”€â”€â”€â”
     â”‚                                       â”‚
     â”œâ”€â†’ PREPROCESS â”€â”€â†’ Reprojected â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                       â”‚
     â”œâ”€â†’ FEATURES â”€â”€â”€â”€â†’ NDVI/NDBI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                       â”‚
     â”œâ”€â†’ TRAIN â”€â”€â”€â”€â”€â”€â”€â†’ Model weights â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                       â”‚
     â”œâ”€â†’ EVALUATE â”€â”€â”€â”€â†’ metrics.json â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                       â”‚
     â”œâ”€â†’ INDICATORS â”€â”€â†’ indicators.json â”€â”€â”€â”€â”¤
     â”‚                                       â”‚
     â”œâ”€â†’ PUBLISH â”€â”€â”€â”€â”€â†’ COG + PNG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                       â”‚
     â””â”€â†’ REPORT â”€â”€â”€â”€â”€â”€â†’ HTML/PDF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     gs://gh-exports-*/
```

---

## Infrastructure Components

### GCP Resources

| Resource | Name | Purpose |
|----------|------|---------|
| Project | `genhack-heat-dev` | Isolated environment |
| Cloud Run Job | `heat-downscaling-pipeline` | Pipeline execution |
| Artifact Registry | `europe-docker.pkg.dev/.../heat` | Container images |
| GCS Buckets | `gh-raw-*`, `gh-intermediate-*`, etc. | Data storage |
| KMS | `gh-ring/gh-key` | CMEK encryption |
| Service Account | `gh-pipeline-sa@...` | Job identity |

### Docker Image Stack

```dockerfile
Base: python:3.11-slim
â”œâ”€â”€ GDAL 3.x (geospatial I/O)
â”œâ”€â”€ PROJ 9.x (coordinate transforms)
â”œâ”€â”€ rasterio (Python GDAL bindings)
â”œâ”€â”€ xarray (n-dimensional arrays)
â”œâ”€â”€ rioxarray (raster extensions)
â”œâ”€â”€ geopandas (vector data)
â”œâ”€â”€ matplotlib (plotting)
â””â”€â”€ weasyprint (PDF generation)
```

**Image Size**: ~2.0 GB (optimized multi-stage build)

---

## Security & Isolation

### Clean-Room Principles

âœ… **Separate project** (genhack-heat-dev â‰  mental-journal-dev)  
âœ… **No shared buckets** (gh- prefix vs mj- prefix)  
âœ… **Separate KMS keys** (gh-ring vs mj-ring)  
âœ… **Separate service accounts** (no cross-project IAM)  
âœ… **CI/CD checks** (block Kura references)

### IAM Roles (gh-pipeline-sa)

- `roles/run.admin` - Manage Cloud Run resources
- `roles/run.invoker` - Execute jobs
- `roles/storage.admin` - Read/write GCS
- `roles/artifactregistry.reader` - Pull images
- `roles/logging.logWriter` - Write logs
- `roles/monitoring.metricWriter` - Write metrics
- `roles/cloudkms.cryptoKeyEncrypterDecrypter` - Use KMS key

---

## Scalability Considerations

### Phase 1 (Current)

- Single city (Paris)
- 3-day period
- 128Ã—128 rasters
- Sequential execution
- ~60s total runtime

### Phase 2+ (Future)

- Multi-city processing (5-10 cities)
- Full summer season (June-August)
- High-resolution (1024Ã—1024+)
- Parallel tile processing
- GPU-accelerated training
- Distributed training (Cloud TPU)

### Optimization Strategies

1. **Tiling**: Split large areas into manageable tiles
2. **Caching**: Store preprocessed data for reuse
3. **Lazy loading**: Use xarray Dask integration
4. **Parallelization**: Cloud Run Jobs with `--tasks` flag
5. **Cloud Storage**: Use Parallel Composite Uploads

---

## Monitoring & Observability

### Logs

```bash
# View job logs
gcloud logging read \
  "resource.type=cloud_run_job AND \
   resource.labels.job_name=heat-downscaling-pipeline" \
  --limit=50 \
  --format=json
```

### Metrics

- Execution duration
- Memory/CPU utilization
- GCS bandwidth usage
- Stage-specific timings

### Alerts (Future)

- Job failure notifications
- Cost threshold alerts
- Data quality checks

---

## Tech Stack Summary

| Layer | Technologies |
|-------|-------------|
| **Compute** | Cloud Run Jobs, Docker |
| **Storage** | Cloud Storage (CMEK), Artifact Registry |
| **Security** | KMS, IAM, Service Accounts |
| **Geospatial** | GDAL, PROJ, rasterio, xarray |
| **ML** | (Phase 2+) PyTorch, U-Net, SRGAN |
| **CI/CD** | GitHub Actions, Cloud Build |
| **Observability** | Cloud Logging, Cloud Monitoring |

---

## Evolution Path

```
Phase 0: Infrastructure âœ…
    â†“
Phase 1: Mock pipeline âœ…
    â†“
Phase 2: Real data ingestion
    â†“
Phase 3: ML model training
    â†“
Phase 4: Multi-city analysis
    â†“
Production: Operational system
```

**Current Status**: Phase 1 complete, ready for Phase 2
