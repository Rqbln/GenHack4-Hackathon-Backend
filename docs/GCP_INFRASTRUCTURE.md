# ğŸ—ï¸ Infrastructure GCP - GenHack Heat Downscaling Pipeline

> **Documentation complÃ¨te de la stack Google Cloud Platform dÃ©ployÃ©e**  
> **Projet** : `genhack-heat-dev`  
> **Date d'analyse** : 9 novembre 2025  
> **Statut** : Phase 1 complÃ¨te, Phase 2 en cours

---

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Ressources dÃ©ployÃ©es](#ressources-dÃ©ployÃ©es)
3. [Architecture dÃ©taillÃ©e](#architecture-dÃ©taillÃ©e)
4. [SÃ©curitÃ© et IAM](#sÃ©curitÃ©-et-iam)
5. [Ã‰tat actuel vs objectifs](#Ã©tat-actuel-vs-objectifs)
6. [Points Ã  amÃ©liorer](#points-Ã -amÃ©liorer)
7. [Roadmap de dÃ©veloppement](#roadmap-de-dÃ©veloppement)

---

## ğŸ¯ Vue d'ensemble

### Projet GCP

- **Project ID** : `genhack-heat-dev`
- **Project Number** : `65076813859`
- **RÃ©gion principale** : `europe-west1`
- **Statut** : âœ… Actif et opÃ©rationnel

### Objectif

Pipeline serverless de downscaling climatique pour l'analyse des Ã®lots de chaleur urbains, dÃ©ployÃ©e sur Google Cloud Platform avec isolation complÃ¨te et sÃ©curitÃ© renforcÃ©e.

### Phase actuelle

- âœ… **Phase 0** : Infrastructure de base (complÃ¨te)
- âœ… **Phase 1** : Pipeline mock avec donnÃ©es synthÃ©tiques (complÃ¨te)
- ğŸ”„ **Phase 2** : IntÃ©gration donnÃ©es rÃ©elles (en cours)

---

## ğŸ›ï¸ Ressources dÃ©ployÃ©es

### 1. Cloud Run Jobs

#### Job principal : `heat-downscaling-pipeline`

**Configuration** :
- **RÃ©gion** : `europe-west1`
- **Image Docker** : `europe-docker.pkg.dev/genhack-heat-dev/heat/gh-pipeline:7671c2123c1e325fd18cfeef7ed44669108e1fea`
- **Service Account** : `gh-pipeline-sa@genhack-heat-dev.iam.gserviceaccount.com`
- **Ressources** :
  - CPU : 2 vCPU
  - MÃ©moire : 4 GiB
  - Timeout : 3600s (1 heure)
  - Max retries : 1

**Environnement** :
```yaml
PROJECT_ID: genhack-heat-dev
BUCKET_EXPORTS: gh-exports-genhack-heat-dev
BUCKET_CONFIGS: gh-configs-genhack-heat-dev
```

**Arguments** :
- `--config configs/paris_2022_mock.yml`

**Statut** :
- âœ… Job crÃ©Ã© : 8 novembre 2025, 15:58:19 UTC
- âœ… DerniÃ¨re exÃ©cution rÃ©ussie : 8 novembre 2025, 16:22:57 UTC
- âœ… ExÃ©cutions totales : 3 (1 rÃ©ussie, 2 Ã©chouÃ©es initialement)

**DerniÃ¨re exÃ©cution** :
- **Execution ID** : `heat-downscaling-pipeline-7rrjz`
- **Statut** : âœ… `EXECUTION_SUCCEEDED`
- **Date** : 8 novembre 2025, 16:22:57 UTC
- **ComplÃ©tion** : 8 novembre 2025, 16:23:54 UTC (~1 minute)

---

### 2. Cloud Storage (GCS) - 11 Buckets

Tous les buckets sont :
- **RÃ©gion** : `EUROPE-WEST1`
- **Classe de stockage** : `STANDARD`
- **Uniform Bucket-Level Access** : âœ… ActivÃ©
- **Public Access Prevention** : âœ… HÃ©ritÃ© (bloquÃ©)
- **Soft Delete** : âœ… ActivÃ© (7 jours de rÃ©tention)
- **Chiffrement** : CMEK avec clÃ© KMS `gh-key`

#### Buckets par catÃ©gorie

##### Raw Data (DonnÃ©es brutes)
1. **`gh-raw-era5-genhack-heat-dev`**
   - **Usage** : Stockage des donnÃ©es ERA5 brutes
   - **Contenu attendu** : Fichiers NetCDF/GRIB depuis Copernicus CDS
   - **Statut** : âœ… CrÃ©Ã©, vide (Phase 2)

2. **`gh-raw-sentinel2-genhack-heat-dev`**
   - **Usage** : Stockage des images Sentinel-2 brutes
   - **Contenu attendu** : GeoTIFF depuis Google Earth Engine
   - **Statut** : âœ… CrÃ©Ã©, vide (Phase 2)

3. **`gh-raw-osm-genhack-heat-dev`**
   - **Usage** : Stockage des donnÃ©es OpenStreetMap
   - **Contenu attendu** : GeoJSON/PBF avec bÃ¢timents, routes, etc.
   - **Statut** : âœ… CrÃ©Ã©, vide (Phase 2)

##### Intermediate Data (DonnÃ©es intermÃ©diaires)
4. **`gh-intermediate-reprojected-genhack-heat-dev`**
   - **Usage** : Rasters reprojetÃ©s (Ã©tape preprocessing)
   - **Statut** : âœ… CrÃ©Ã©, utilisÃ© par la pipeline

5. **`gh-intermediate-preprocessed-genhack-heat-dev`**
   - **Usage** : DonnÃ©es prÃ©processÃ©es (normalisation, masques)
   - **Statut** : âœ… CrÃ©Ã©, utilisÃ© par la pipeline

##### Features & Models
6. **`gh-models-checkpoints-genhack-heat-dev`**
   - **Usage** : Checkpoints des modÃ¨les ML (U-Net, SRGAN)
   - **Statut** : âœ… CrÃ©Ã©, vide (Phase 3)

7. **`gh-models-experiments-genhack-heat-dev`**
   - **Usage** : MÃ©triques et logs d'entraÃ®nement (MLflow, TensorBoard)
   - **Statut** : âœ… CrÃ©Ã©, vide (Phase 3)

##### Exports (Sorties finales)
8. **`gh-exports-geotiff-genhack-heat-dev`**
   - **Usage** : GeoTIFF finaux (tempÃ©rature, NDVI, NDBI)
   - **Format** : Cloud Optimized GeoTIFF (COG)
   - **Statut** : âœ… CrÃ©Ã©, **vide actuellement** âš ï¸

9. **`gh-exports-zarr-genhack-heat-dev`**
   - **Usage** : Exports Zarr pour analyses multi-dimensionnelles
   - **Statut** : âœ… CrÃ©Ã©, vide (Phase 2+)

##### Configuration & Logs
10. **`gh-configs-genhack-heat-dev`**
    - **Usage** : Fichiers de configuration YAML
    - **Contenu** : Configs pour diffÃ©rentes villes/pÃ©riodes
    - **Statut** : âœ… CrÃ©Ã©, utilisÃ©

11. **`gh-logs-genhack-heat-dev`**
    - **Usage** : Logs d'exÃ©cution de la pipeline
    - **Statut** : âœ… CrÃ©Ã©, utilisÃ©

**âš ï¸ Observation** : Le bucket `gh-exports-geotiff-genhack-heat-dev` est vide, ce qui suggÃ¨re que les outputs ne sont pas uploadÃ©s vers GCS (probablement Ã©crits localement dans le container).

---

### 3. Artifact Registry

#### Repository : `heat`

**Configuration** :
- **Location** : `europe`
- **Format** : `DOCKER`
- **Mode** : `STANDARD_REPOSITORY`
- **Description** : "GenHack Heat Downscaling - Isolated from Kura"
- **Labels** :
  - `isolation=strict`
  - `project=genhack`
- **Chiffrement** : Google-managed key
- **Taille totale** : ~1.7 GB

**Images Docker** :
- **Image principale** : `gh-pipeline`
- **DerniÃ¨re image** : `sha256:2c260866833bba263a89e2f34949f4fbcddd3516dc553bb4a7de543695664793`
- **Taille** : ~478 MB (478,606,415 bytes)
- **Tag utilisÃ©** : `7671c2123c1e325fd18cfeef7ed44669108e1fea` (commit hash)

**Images disponibles** :
- Plusieurs versions avec tags SHA256
- Build time : 8 novembre 2025, 16:22:17 UTC

---

### 4. Cloud KMS (Key Management Service)

#### Keyring : `gh-ring`

**Configuration** :
- **Location** : `europe-west1`
- **Statut** : âœ… Actif

#### ClÃ© de chiffrement : `gh-key`

**Configuration** :
- **Purpose** : `ENCRYPT_DECRYPT`
- **Algorithm** : `GOOGLE_SYMMETRIC_ENCRYPTION`
- **Protection Level** : `SOFTWARE`
- **Statut** : âœ… `ENABLED`
- **Primary ID** : 1
- **Primary State** : `ENABLED`

**Usage** : Chiffrement CMEK pour tous les buckets GCS

---

### 5. Service Accounts

#### Service Account principal : `gh-pipeline-sa`

**Email** : `gh-pipeline-sa@genhack-heat-dev.iam.gserviceaccount.com`  
**Display Name** : "GenHack Pipeline Service Account"  
**Description** : "Isolated SA for heat downscaling pipeline - NO Kura access"  
**Unique ID** : `107878297922802250363`  
**Statut** : âœ… Actif

**Permissions IAM (Project-level)** :
- âœ… `roles/storage.admin` - AccÃ¨s complet aux buckets
- âœ… `roles/run.admin` - Gestion Cloud Run
- âœ… `roles/run.invoker` - ExÃ©cution Cloud Run Jobs
- âœ… `roles/artifactregistry.reader` - Lecture Artifact Registry
- âœ… `roles/artifactregistry.writer` - Ã‰criture Artifact Registry
- âœ… `roles/cloudkms.cryptoKeyEncrypterDecrypter` - Chiffrement/dÃ©chiffrement KMS
- âœ… `roles/logging.logWriter` - Ã‰criture logs
- âœ… `roles/monitoring.metricWriter` - MÃ©triques monitoring
- âœ… `roles/iam.serviceAccountUser` - Utilisation du service account

**Permissions IAM (Service Account-level)** :
- âœ… `roles/iam.serviceAccountUser` (sur lui-mÃªme)

#### Service Account Compute Engine (par dÃ©faut)

**Email** : `65076813859-compute@developer.gserviceaccount.com`  
**Usage** : Service account par dÃ©faut pour Compute Engine  
**Permissions** : `roles/editor` (trop permissif âš ï¸)

---

### 6. APIs activÃ©es

Les APIs suivantes sont activÃ©es dans le projet :

1. âœ… `run.googleapis.com` - Cloud Run
2. âœ… `artifactregistry.googleapis.com` - Artifact Registry
3. âœ… `storage.googleapis.com` - Cloud Storage
4. âœ… `cloudkms.googleapis.com` - Cloud KMS
5. âœ… `logging.googleapis.com` - Cloud Logging
6. âœ… `monitoring.googleapis.com` - Cloud Monitoring
7. âœ… `cloudbuild.googleapis.com` - Cloud Build
8. âœ… `eventarc.googleapis.com` - Eventarc
9. âœ… `cloudscheduler.googleapis.com` - Cloud Scheduler
10. âœ… `compute.googleapis.com` - Compute Engine

**APIs manquantes (pour Phase 2)** :
- âŒ `earthengine.googleapis.com` - Google Earth Engine (pour Sentinel-2)
- âŒ `bigquery.googleapis.com` - BigQuery (optionnel, pour analytics)
- âŒ `aiplatform.googleapis.com` - Vertex AI (pour modÃ¨les ML, Phase 3)

---

### 7. IAM - Utilisateurs et permissions

#### Utilisateurs avec accÃ¨s au projet

**Owner** :
- `queriauxrobin@gmail.com` - âœ… Owner complet

**Editors** (trop permissif âš ï¸) :
- `arnaud.durand97@gmail.com`
- `besbesomar@gmail.com`
- `dermierayan@gmail.com`
- `romain.mallet2004@gmail.com`

**Artifact Registry Admin** :
- `arnaud.durand97@gmail.com`
- `besbesomar@gmail.com`
- `dermierayan@gmail.com`
- `romain.mallet2004@gmail.com`

**Cloud Run Admin** :
- `arnaud.durand97@gmail.com`
- `besbesomar@gmail.com`
- `dermierayan@gmail.com`
- `romain.mallet2004@gmail.com`
- Service accounts Cloud Build

**Storage Admin** :
- `gh-pipeline-sa@genhack-heat-dev.iam.gserviceaccount.com`
- `arnaud.durand97@gmail.com`
- `besbesomar@gmail.com`
- `dermierayan@gmail.com`
- `romain.mallet2004@gmail.com`

---

## ğŸ—ï¸ Architecture dÃ©taillÃ©e

### Flux de donnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLOUD RUN JOB                            â”‚
â”‚              heat-downscaling-pipeline                      â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Docker Container (4GB RAM, 2 CPU)                   â”‚  â”‚
â”‚  â”‚  Image: gh-pipeline:7671c212...                      â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Pipeline Stages:                                    â”‚  â”‚
â”‚  â”‚  1. Ingest (mock) â†’ 2. Preprocess â†’ 3. Features     â”‚  â”‚
â”‚  â”‚  4. Train (stub) â†’ 5. Evaluate â†’ 6. Indicators      â”‚  â”‚
â”‚  â”‚  7. Publish â†’ 8. Report                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GCS Buckets â”‚ â”‚ Artifact Reg â”‚ â”‚ Cloud Loggingâ”‚
â”‚  (11 buckets)â”‚ â”‚  (heat repo) â”‚ â”‚  (logs)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline stages (8 Ã©tapes)

1. **Ingest** (`src/ingest.py`)
   - Phase 1 : GÃ©nÃ¨re donnÃ©es mock (128Ã—128 rasters)
   - Phase 2 : TÃ©lÃ©charge ERA5, Sentinel-2, OSM

2. **Preprocess** (`src/preprocess.py`)
   - Reprojection vers EPSG:3857
   - Resampling pour aligner rÃ©solutions
   - âœ… ImplÃ©mentÃ© et fonctionnel

3. **Features** (`src/features.py`)
   - Calcul NDVI, NDBI
   - Phase 1 : Mock calculations
   - Phase 2 : Vraies images Sentinel-2

4. **Train** (`src/train.py`)
   - Phase 1 : Stub (pas d'entraÃ®nement)
   - Phase 3 : U-Net pour downscaling

5. **Evaluate** (`src/evaluate.py`)
   - Calcul mÃ©triques (RMSE, MAE, RÂ²)
   - âœ… ImplÃ©mentÃ©

6. **Indicators** (`src/indicators.py`)
   - IntensitÃ©, durÃ©e, Ã©tendue, UHI
   - âœ… ImplÃ©mentÃ© (mock)

7. **Publish** (`src/publish.py`)
   - Export GeoTIFF, PNG
   - âš ï¸ **ProblÃ¨me** : N'upload pas vers GCS (Ã©crit localement)

8. **Report** (`src/report.py`)
   - GÃ©nÃ©ration HTML/PDF
   - âœ… ImplÃ©mentÃ©

---

## ğŸ”’ SÃ©curitÃ© et IAM

### Points forts âœ…

1. **Isolation complÃ¨te**
   - Projet GCP dÃ©diÃ© (`genhack-heat-dev`)
   - Aucun lien avec le projet Kura (`mental-journal-dev`)
   - Service account isolÃ© avec description explicite

2. **Chiffrement CMEK**
   - Tous les buckets chiffrÃ©s avec clÃ© KMS `gh-key`
   - ClÃ© activÃ©e et opÃ©rationnelle

3. **Uniform Bucket-Level Access**
   - Tous les buckets en mode uniform
   - Public access prevention activÃ©

4. **Soft Delete**
   - RÃ©tention de 7 jours pour rÃ©cupÃ©ration

5. **Service Account avec permissions minimales**
   - `gh-pipeline-sa` a uniquement les permissions nÃ©cessaires
   - Pas d'accÃ¨s cross-project

### Points Ã  amÃ©liorer âš ï¸

1. **Permissions trop larges pour utilisateurs**
   - 4 utilisateurs avec `roles/editor` (accÃ¨s complet)
   - **Recommandation** : RÃ©duire Ã  `roles/viewer` + rÃ´les spÃ©cifiques

2. **Service Account Compute Engine**
   - `65076813859-compute@developer.gserviceaccount.com` a `roles/editor`
   - **Recommandation** : Limiter les permissions

3. **Pas de VPC**
   - Cloud Run utilise le rÃ©seau public
   - **Recommandation** : Configurer VPC connector pour Phase 2+ (si accÃ¨s privÃ© nÃ©cessaire)

4. **Pas de secrets management**
   - Pas de Secret Manager pour API keys (Copernicus, Earth Engine)
   - **Recommandation** : Utiliser Secret Manager pour Phase 2

---

## ğŸ“Š Ã‰tat actuel vs objectifs

### Phase 1 : Mock Data Pipeline âœ…

| Composant | Statut | DÃ©tails |
|-----------|--------|---------|
| Infrastructure GCP | âœ… | 11 buckets, KMS, Artifact Registry |
| Cloud Run Job | âœ… | DÃ©ployÃ© et exÃ©cutÃ© avec succÃ¨s |
| Pipeline 8 stages | âœ… | Tous implÃ©mentÃ©s (mock) |
| Docker image | âœ… | Build et push rÃ©ussis |
| CI/CD | âœ… | GitHub Actions configurÃ© |
| Tests | âœ… | Tests de contrats validÃ©s |
| Documentation | âœ… | README, ARCHITECTURE, SCHEMAS |

**RÃ©sultats** :
- âœ… Pipeline s'exÃ©cute en ~1 minute
- âœ… GÃ©nÃ¨re donnÃ©es mock (tempÃ©rature, NDVI, NDBI)
- âœ… Produit rapports HTML/PDF
- âš ï¸ **ProblÃ¨me** : Outputs non uploadÃ©s vers GCS

### Phase 2 : DonnÃ©es rÃ©elles ğŸ”„

| Composant | Statut | DÃ©tails |
|-----------|--------|---------|
| IntÃ©gration ERA5 | âŒ | Pas d'API Copernicus CDS |
| IntÃ©gration Sentinel-2 | âŒ | Pas d'API Google Earth Engine |
| IntÃ©gration OSM | âŒ | Pas d'extraction Overpass API |
| Upload GCS | âŒ | Outputs Ã©crits localement uniquement |
| Validation stations | âŒ | Pas d'intÃ©gration ECA&D |

**APIs nÃ©cessaires** :
- âŒ `earthengine.googleapis.com` - Non activÃ©e
- âŒ Secret Manager - Non configurÃ© pour API keys

### Phase 3 : Machine Learning ğŸ”œ

| Composant | Statut | DÃ©tails |
|-----------|--------|---------|
| ModÃ¨le U-Net | âŒ | Stub uniquement |
| Training pipeline | âŒ | Pas d'infrastructure Vertex AI |
| Checkpoints | âŒ | Bucket crÃ©Ã© mais vide |
| Experiments tracking | âŒ | Pas de MLflow/TensorBoard |

**Infrastructure nÃ©cessaire** :
- âŒ Vertex AI Workbench ou Training
- âŒ GPU instances (pour training)
- âŒ MLflow ou TensorBoard

---

## âš ï¸ Points Ã  amÃ©liorer

### 1. Upload des outputs vers GCS âŒ

**ProblÃ¨me** : Le bucket `gh-exports-geotiff-genhack-heat-dev` est vide, alors que la pipeline s'exÃ©cute avec succÃ¨s.

**Cause probable** : Le stage `publish.py` Ã©crit les fichiers localement dans le container mais ne les upload pas vers GCS.

**Solution** :
```python
# Dans src/publish.py, ajouter upload GCS :
from google.cloud import storage

def upload_to_gcs(local_path: Path, gcs_path: str):
    client = storage.Client()
    bucket = client.bucket("gh-exports-geotiff-genhack-heat-dev")
    blob = bucket.blob(gcs_path)
    blob.upload_from_filename(str(local_path))
```

**PrioritÃ©** : ğŸ”´ **Haute** - Bloque la Phase 2

---

### 2. Permissions IAM trop larges âš ï¸

**ProblÃ¨me** : 4 utilisateurs ont `roles/editor` (accÃ¨s complet au projet).

**Recommandation** :
- RÃ©duire Ã  `roles/viewer` pour consultation
- Ajouter `roles/storage.objectViewer` pour lire les buckets
- Ajouter `roles/run.viewer` pour voir les jobs
- CrÃ©er des rÃ´les custom si nÃ©cessaire

**PrioritÃ©** : ğŸŸ¡ **Moyenne** - SÃ©curitÃ©

---

### 3. Pas de Secret Manager âš ï¸

**ProblÃ¨me** : Les API keys (Copernicus CDS, Earth Engine) seront probablement hardcodÃ©es ou en variables d'environnement.

**Recommandation** :
- CrÃ©er des secrets dans Secret Manager
- Modifier le service account pour accÃ©der aux secrets
- Utiliser `google-cloud-secret-manager` dans le code

**PrioritÃ©** : ğŸŸ¡ **Moyenne** - SÃ©curitÃ© pour Phase 2

---

### 4. APIs manquantes âŒ

**APIs non activÃ©es** :
- `earthengine.googleapis.com` - Pour Sentinel-2
- `secretmanager.googleapis.com` - Pour gestion des secrets
- `aiplatform.googleapis.com` - Pour Vertex AI (Phase 3)

**PrioritÃ©** : ğŸ”´ **Haute** pour Earth Engine, ğŸŸ¡ **Moyenne** pour les autres

---

### 5. Pas de monitoring avancÃ© âš ï¸

**ProblÃ¨me** : Seul `roles/monitoring.metricWriter` est configurÃ©, mais pas de dashboards ou alertes.

**Recommandation** :
- CrÃ©er des dashboards Cloud Monitoring
- Configurer des alertes (Ã©checs de jobs, utilisation storage)
- MÃ©triques custom (temps d'exÃ©cution, taille outputs)

**PrioritÃ©** : ğŸŸ¢ **Basse** - Nice to have

---

### 6. Pas de CI/CD pour tests automatiques âš ï¸

**ProblÃ¨me** : CI/CD existe mais ne lance pas les tests automatiquement.

**Recommandation** :
- Ajouter Ã©tape `make test` dans GitHub Actions
- Tests de rÃ©gression avant dÃ©ploiement
- Validation des schÃ©mas JSON

**PrioritÃ©** : ğŸŸ¡ **Moyenne** - QualitÃ©

---

### 7. Buckets inutilisÃ©s âš ï¸

**Buckets crÃ©Ã©s mais vides** :
- `gh-exports-zarr-genhack-heat-dev` - Pas d'implÃ©mentation Zarr
- `gh-models-checkpoints-genhack-heat-dev` - Phase 3
- `gh-models-experiments-genhack-heat-dev` - Phase 3

**Recommandation** :
- Garder pour Phase 3 (modÃ¨les ML)
- Documenter l'usage prÃ©vu

**PrioritÃ©** : ğŸŸ¢ **Basse** - Pas urgent

---

## ğŸ—ºï¸ Roadmap de dÃ©veloppement

### Phase 2 - IntÃ©gration donnÃ©es rÃ©elles (PrioritÃ© haute)

#### 2.1. Configuration APIs et secrets

- [ ] Activer `earthengine.googleapis.com`
- [ ] Activer `secretmanager.googleapis.com`
- [ ] CrÃ©er secrets dans Secret Manager :
  - `copernicus-cds-api-key`
  - `earthengine-service-account-key`
- [ ] Modifier `gh-pipeline-sa` pour accÃ©der aux secrets

#### 2.2. Fix upload GCS

- [ ] Modifier `src/publish.py` pour uploader vers GCS
- [ ] Tester avec donnÃ©es mock
- [ ] VÃ©rifier que les fichiers apparaissent dans `gh-exports-geotiff-genhack-heat-dev`

#### 2.3. IntÃ©gration ERA5

- [ ] Installer `cdsapi` dans `requirements.txt`
- [ ] ImplÃ©menter tÃ©lÃ©chargement depuis Copernicus CDS
- [ ] Upload vers `gh-raw-era5-genhack-heat-dev`
- [ ] Tester avec Paris 2022

#### 2.4. IntÃ©gration Sentinel-2

- [ ] Installer `earthengine-api` dans `requirements.txt`
- [ ] Authentifier avec service account
- [ ] ImplÃ©menter requÃªte Google Earth Engine
- [ ] Calcul NDVI/NDBI sur vraies images
- [ ] Upload vers `gh-raw-sentinel2-genhack-heat-dev`

#### 2.5. IntÃ©gration OSM (optionnel)

- [ ] Installer `overpy` ou `osmnx`
- [ ] Extraire bÃ¢timents, routes, espaces verts
- [ ] Upload vers `gh-raw-osm-genhack-heat-dev`

#### 2.6. Validation stations mÃ©tÃ©o

- [ ] TÃ©lÃ©charger donnÃ©es ECA&D
- [ ] SÃ©lectionner stations dans zone d'Ã©tude
- [ ] Comparer ERA5 vs stations
- [ ] Calculer mÃ©triques de validation

---

### Phase 3 - Machine Learning (PrioritÃ© moyenne)

#### 3.1. Infrastructure Vertex AI

- [ ] Activer `aiplatform.googleapis.com`
- [ ] CrÃ©er bucket pour checkpoints (dÃ©jÃ  fait)
- [ ] Configurer Vertex AI Workbench ou Training

#### 3.2. ModÃ¨le U-Net

- [ ] ImplÃ©menter architecture U-Net
- [ ] Training pipeline avec Vertex AI
- [ ] Sauvegarde checkpoints dans `gh-models-checkpoints-genhack-heat-dev`
- [ ] Tracking expÃ©riences dans `gh-models-experiments-genhack-heat-dev`

#### 3.3. IntÃ©gration dans pipeline

- [ ] Modifier `src/train.py` pour utiliser Vertex AI
- [ ] Modifier `src/evaluate.py` pour charger le modÃ¨le
- [ ] Tester end-to-end

---

### Phase 4 - API REST (PrioritÃ© moyenne)

#### 4.1. Cloud Run Service (pas Job)

- [ ] CrÃ©er Cloud Run Service (HTTP)
- [ ] Endpoints REST :
  - `GET /api/cities`
  - `GET /api/reports/{city}`
  - `GET /api/heatmap/{city}`
  - `POST /api/analyze`
  - `GET /api/indicators/{city}`

#### 4.2. Authentification

- [ ] Configurer IAP (Identity-Aware Proxy) ou API keys
- [ ] Limiter accÃ¨s aux membres de l'Ã©quipe

#### 4.3. IntÃ©gration frontend

- [ ] Documenter API (OpenAPI/Swagger)
- [ ] Tester avec frontend

---

### Phase 5 - AmÃ©liorations sÃ©curitÃ© (PrioritÃ© moyenne)

#### 5.1. RÃ©duction permissions IAM

- [ ] RÃ©duire `roles/editor` â†’ `roles/viewer` + rÃ´les spÃ©cifiques
- [ ] Limiter permissions service account Compute Engine
- [ ] Audit des permissions actuelles

#### 5.2. VPC (si nÃ©cessaire)

- [ ] Ã‰valuer besoin de VPC connector
- [ ] Configurer si accÃ¨s privÃ© requis

#### 5.3. Monitoring et alertes

- [ ] CrÃ©er dashboards Cloud Monitoring
- [ ] Configurer alertes (Ã©checs jobs, storage usage)
- [ ] MÃ©triques custom

---

## ğŸ“ˆ MÃ©triques et coÃ»ts

### CoÃ»ts estimÃ©s (Phase 1)

**Cloud Run Jobs** :
- ExÃ©cutions : ~3 exÃ©cutions
- DurÃ©e moyenne : ~1 minute
- CoÃ»t : ~$0.01 (nÃ©gligeable)

**Cloud Storage** :
- Buckets : 11 buckets
- DonnÃ©es stockÃ©es : ~0 GB (vides)
- CoÃ»t : ~$0 (gratuit jusqu'Ã  5 GB)

**Artifact Registry** :
- Images : ~1.7 GB
- CoÃ»t : ~$0.05/mois

**Cloud KMS** :
- ClÃ©s actives : 1
- OpÃ©rations : ~1000/mois
- CoÃ»t : ~$1/mois

**Total Phase 1** : ~$1-2/mois

### CoÃ»ts estimÃ©s (Phase 2+)

**Cloud Run Jobs** :
- ExÃ©cutions : ~10-20/mois
- DurÃ©e : ~5-10 minutes
- CoÃ»t : ~$0.50-1/mois

**Cloud Storage** :
- DonnÃ©es : ~50-100 GB (ERA5, Sentinel-2)
- CoÃ»t : ~$1-2/mois

**Vertex AI (Phase 3)** :
- Training : ~$10-50/mois (GPU instances)
- Prediction : ~$1-5/mois

**Total Phase 2+** : ~$15-60/mois

---

## âœ… Checklist de vÃ©rification

### Infrastructure de base
- [x] Projet GCP crÃ©Ã© et actif
- [x] 11 buckets GCS crÃ©Ã©s avec CMEK
- [x] Artifact Registry configurÃ©
- [x] Cloud KMS keyring et clÃ© crÃ©Ã©s
- [x] Service account avec permissions minimales
- [x] APIs nÃ©cessaires activÃ©es (Phase 1)
- [x] Cloud Run Job dÃ©ployÃ© et fonctionnel

### Pipeline
- [x] 8 stages implÃ©mentÃ©s (mock)
- [x] Docker image build et push
- [x] ExÃ©cution rÃ©ussie
- [ ] Upload outputs vers GCS âŒ
- [ ] IntÃ©gration donnÃ©es rÃ©elles âŒ

### SÃ©curitÃ©
- [x] Isolation complÃ¨te (projet dÃ©diÃ©)
- [x] Chiffrement CMEK
- [x] Uniform bucket-level access
- [ ] Permissions IAM optimisÃ©es âš ï¸
- [ ] Secret Manager configurÃ© âŒ

### Documentation
- [x] README complet
- [x] Architecture documentÃ©e
- [x] SchÃ©mas JSON documentÃ©s
- [x] Scripts de dÃ©ploiement
- [x] Makefile avec commandes

---

## ğŸ”— Liens utiles

### Console GCP
- **Project** : https://console.cloud.google.com/?project=genhack-heat-dev
- **Cloud Run Jobs** : https://console.cloud.google.com/run/jobs?project=genhack-heat-dev
- **Cloud Storage** : https://console.cloud.google.com/storage/browser?project=genhack-heat-dev
- **Artifact Registry** : https://console.cloud.google.com/artifacts?project=genhack-heat-dev
- **Cloud KMS** : https://console.cloud.google.com/security/kms?project=genhack-heat-dev
- **IAM** : https://console.cloud.google.com/iam-admin/iam?project=genhack-heat-dev
- **Logs** : https://console.cloud.google.com/logs?project=genhack-heat-dev

### Commandes utiles

```bash
# VÃ©rifier le projet actuel
gcloud config get-value project

# Lister les buckets
gsutil ls

# Voir les exÃ©cutions du job
gcloud run jobs executions list --job=heat-downscaling-pipeline --region=europe-west1

# Voir les logs
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=heat-downscaling-pipeline" --limit=50

# DÃ©crire le job
gcloud run jobs describe heat-downscaling-pipeline --region=europe-west1

# ExÃ©cuter le job
gcloud run jobs execute heat-downscaling-pipeline --region=europe-west1 --wait
```

---

## ğŸ“ Notes importantes

1. **Isolation** : Le projet est complÃ¨tement isolÃ© du projet Kura. Aucun bucket, service account ou ressource n'est partagÃ©.

2. **Phase 1 complÃ¨te** : L'infrastructure de base est opÃ©rationnelle. La pipeline s'exÃ©cute avec succÃ¨s mais utilise des donnÃ©es mock.

3. **Phase 2 prioritaire** : L'intÃ©gration des donnÃ©es rÃ©elles (ERA5, Sentinel-2) est la prochaine Ã©tape critique.

4. **Upload GCS** : Le problÃ¨me d'upload des outputs vers GCS doit Ãªtre rÃ©solu avant de passer Ã  la Phase 2.

5. **SÃ©curitÃ©** : Les permissions IAM peuvent Ãªtre optimisÃ©es, mais ne bloquent pas le dÃ©veloppement.

---

**DerniÃ¨re mise Ã  jour** : 9 novembre 2025  
**Auteur** : Analyse automatique via `gcloud` CLI  
**Version** : 1.0.0

