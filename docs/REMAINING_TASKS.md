# üìã √âtat des Lieux et T√¢ches Restantes - GenHack 2025

**Date** : 18 D√©cembre 2025  
**Statut** : Code structurellement complet, mais donn√©es r√©elles et entra√Ænement non effectu√©s

---

## ‚úÖ Ce qui a √©t√© fait

### Backend
- ‚úÖ Structure compl√®te du code (ETL, gap_filling, baseline, finetuning, etc.)
- ‚úÖ API simple fonctionnelle en local (`api_simple.py`)
- ‚úÖ Tests de structure (13/13 modules)
- ‚úÖ Documentation technique
- ‚úÖ M√©triques mock√©es (`results/all_metrics.json`)

### Frontend
- ‚úÖ Application React 19 + Vite + Tailwind
- ‚úÖ Composants Deck.gl (MapView, StationLayer, HeatmapLayer, etc.)
- ‚úÖ Scrollytelling int√©gr√©
- ‚úÖ Design system complet
- ‚úÖ Build fonctionnel

### Infrastructure
- ‚úÖ Configuration Vercel pr√™te
- ‚úÖ Scripts de test et d'int√©gration
- ‚úÖ Documentation d√©ploiement

---

## ‚ùå Ce qui n'a PAS √©t√© fait

### 1. üî¥ CRITIQUE : Utilisation des Vraies Donn√©es

**Probl√®me** : Le code utilise des donn√©es mock, pas les vraies donn√©es dans `/datasets/`

**Donn√©es disponibles** :
```
/datasets/
‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îú‚îÄ‚îÄ derived-era5-land-daily-statistics/  # ERA5 NetCDF (2020-2025)
‚îÇ   ‚îú‚îÄ‚îÄ sentinel2_ndvi/                      # Sentinel-2 NDVI GeoTIFF
‚îÇ   ‚îî‚îÄ‚îÄ gadm_410_europe.gpkg                 # GADM boundaries
‚îú‚îÄ‚îÄ ECA_blend_tx/                            # ECA&D stations (8572 fichiers)
‚îî‚îÄ‚îÄ ECA_blend_tx.zip                         # Archive ECA&D
```

**T√¢ches √† faire** :
- [ ] **Modifier `src/etl.py`** pour charger les vraies donn√©es au lieu de g√©n√©rer des mocks
  - [ ] Charger ERA5 depuis `datasets/main/derived-era5-land-daily-statistics/`
  - [ ] Charger Sentinel-2 depuis `datasets/main/sentinel2_ndvi/`
  - [ ] Charger ECA&D depuis `datasets/ECA_blend_tx/` ou `ECA_blend_tx.zip`
  - [ ] Charger GADM depuis `datasets/main/gadm_410_europe.gpkg`
- [ ] **Tester l'ETL** avec les vraies donn√©es
- [ ] **Valider** que les donn√©es sont correctement align√©es temporellement
- [ ] **G√©n√©rer** les fichiers Zarr/NetCDF pour le training

**Fichiers √† modifier** :
- `GenHack4-Hackathon-Vertex/src/etl.py` (actuellement utilise des chemins hardcod√©s)
- `GenHack4-Hackathon-Vertex/src/ingest.py` (actuellement g√©n√®re des mocks)

---

### 2. üî¥ CRITIQUE : Entra√Ænement du Mod√®le Prithvi WxC

**Probl√®me** : Le mod√®le n'a jamais √©t√© entra√Æn√©. Le code existe mais n'a pas √©t√© ex√©cut√©.

**T√¢ches √† faire** :
- [ ] **T√©l√©charger Prithvi WxC** depuis Hugging Face
  ```bash
  # Le mod√®le fait ~9GB, n√©cessite GPU
  python3 src/prithvi_setup.py
  ```
- [ ] **Pr√©parer le dataset** pour le fine-tuning
  ```bash
  python3 src/dataset_preparation.py
  ```
  - Cr√©er les paires (LowRes ERA5, HighRes Sentinel-2, Target ECA&D)
  - Split train/validation
- [ ] **Lancer le fine-tuning** avec QLoRA
  ```bash
  python3 src/finetuning.py
  ```
  - N√©cessite GPU (CUDA)
  - Peut prendre plusieurs heures
- [ ] **Sauvegarder le mod√®le** fine-tun√©
- [ ] **G√©n√©rer les pr√©dictions** sur la p√©riode de test

**Fichiers √† ex√©cuter** :
- `GenHack4-Hackathon-Vertex/src/prithvi_setup.py`
- `GenHack4-Hackathon-Vertex/src/dataset_preparation.py`
- `GenHack4-Hackathon-Vertex/src/finetuning.py`

**Ressources n√©cessaires** :
- GPU avec CUDA (minimum 16GB VRAM recommand√©)
- ~50GB d'espace disque pour le mod√®le et les donn√©es

---

### 3. üü° IMPORTANT : G√©n√©ration des Vraies M√©triques

**Probl√®me** : Les m√©triques actuelles sont mock√©es dans `results/all_metrics.json`

**T√¢ches √† faire** :
- [ ] **Ex√©cuter le baseline model** sur les vraies donn√©es
  ```bash
  python3 src/baseline.py
  ```
- [ ] **Ex√©cuter les m√©triques avanc√©es** (Perkins Score, analyse spectrale)
  ```bash
  python3 src/advanced_metrics.py
  ```
- [ ] **Comparer** baseline vs Prithvi fine-tun√©
- [ ] **Valider physiquement** les r√©sultats (PINN)
  ```bash
  python3 src/physics_validation.py
  ```
- [ ] **G√©n√©rer** le fichier `results/all_metrics.json` avec les vraies valeurs
- [ ] **Exporter** les graphiques et figures pour le rapport

**Fichiers √† ex√©cuter** :
- `GenHack4-Hackathon-Vertex/src/baseline.py`
- `GenHack4-Hackathon-Vertex/src/advanced_metrics.py`
- `GenHack4-Hackathon-Vertex/src/physics_validation.py`
- `GenHack4-Hackathon-Vertex/src/export_results.py`

---

### 4. üü° IMPORTANT : D√©ploiement Backend

**Probl√®me** : L'API tourne uniquement en local

**Options de d√©ploiement** :

#### Option A : Cloud Run (GCP) - Recommand√©
- [ ] **Cr√©er** un Dockerfile pour l'API
- [ ] **Configurer** Cloud Run
- [ ] **D√©ployer** l'API
- [ ] **Tester** les endpoints en production
- [ ] **Mettre √† jour** l'URL dans le frontend

#### Option B : Vercel Serverless Functions
- [ ] **Cr√©er** des fonctions serverless pour l'API
- [ ] **Adapter** le code pour Vercel
- [ ] **D√©ployer** sur Vercel
- [ ] **Tester** les endpoints

#### Option C : Railway / Render
- [ ] **Cr√©er** un compte
- [ ] **D√©ployer** l'API
- [ ] **Configurer** les variables d'environnement

**Fichiers √† cr√©er/modifier** :
- `GenHack4-Hackathon-Vertex/Dockerfile` (si Cloud Run)
- `GenHack4-Hackathon-Vertex/vercel.json` (si Vercel)
- `GenHack4-Hackathon-Frontend/src/services/api.ts` (mettre √† jour l'URL)

---

### 5. üü¢ MOYEN : Connexion Frontend aux Vraies Donn√©es

**Probl√®me** : Le frontend utilise des donn√©es mock√©es

**T√¢ches √† faire** :
- [ ] **Modifier** `src/services/api.ts` pour pointer vers l'API d√©ploy√©e
- [ ] **Tester** que les stations ECA&D s'affichent correctement
- [ ] **Tester** que les heatmaps utilisent les vraies donn√©es de temp√©rature
- [ ] **Tester** que les graphiques temporels affichent les vraies s√©ries
- [ ] **Valider** que le scrollytelling fonctionne avec les vraies donn√©es

**Fichiers √† modifier** :
- `GenHack4-Hackathon-Frontend/src/services/api.ts`
- `GenHack4-Hackathon-Frontend/src/hooks/useHeatmapData.ts`
- `GenHack4-Hackathon-Frontend/src/components/MapView.tsx`

---

### 6. üü¢ MOYEN : Gap-Filling Sentinel-2

**Probl√®me** : L'algorithme de gap-filling existe mais n'a pas √©t√© ex√©cut√©

**T√¢ches √† faire** :
- [ ] **Ex√©cuter** le gap-filling sur les vraies donn√©es Sentinel-2
  ```bash
  python3 src/gap_filling.py
  ```
- [ ] **Valider** la qualit√© du gap-filling
- [ ] **Sauvegarder** les rasters NDVI compl√©t√©s

**Fichiers √† ex√©cuter** :
- `GenHack4-Hackathon-Vertex/src/gap_filling.py`

---

### 7. üü¢ MOYEN : G√©n√©ration des Produits Finaux

**T√¢ches √† faire** :
- [ ] **G√©n√©rer** les time series compl√®tes (NetCDF)
  ```bash
  python3 src/product_generation.py
  ```
- [ ] **Calculer** les indicateurs UHI par zone GADM
  ```bash
  python3 src/gadm_indicators.py
  ```
- [ ] **Exporter** tous les r√©sultats pour le rapport

**Fichiers √† ex√©cuter** :
- `GenHack4-Hackathon-Vertex/src/product_generation.py`
- `GenHack4-Hackathon-Vertex/src/gadm_indicators.py`

---

## üéØ Plan d'Action Prioritaire

### Phase 1 : Donn√©es R√©elles (URGENT - 2-3h)
1. Modifier `src/etl.py` pour charger les vraies donn√©es
2. Tester l'ETL avec les donn√©es r√©elles
3. Valider l'alignement temporel

### Phase 2 : Baseline et M√©triques (URGENT - 1-2h)
1. Ex√©cuter le baseline model
2. Calculer les m√©triques baseline
3. G√©n√©rer `results/all_metrics.json` avec vraies valeurs baseline

### Phase 3 : Entra√Ænement Mod√®le (CRITIQUE - 4-8h si GPU disponible)
1. T√©l√©charger Prithvi WxC
2. Pr√©parer le dataset
3. Lancer le fine-tuning (n√©cessite GPU)
4. G√©n√©rer les pr√©dictions

**‚ö†Ô∏è Si pas de GPU disponible** :
- Utiliser Google Colab Pro ou Kaggle
- Ou utiliser un mod√®le pr√©-entra√Æn√© plus petit
- Ou se concentrer sur le baseline uniquement

### Phase 4 : D√©ploiement (IMPORTANT - 1-2h)
1. D√©ployer l'API (Cloud Run ou Vercel)
2. Mettre √† jour le frontend
3. Tester l'int√©gration compl√®te

### Phase 5 : Finalisation (1h)
1. G√©n√©rer les produits finaux
2. Exporter les graphiques
3. Finaliser le rapport

---

## ‚ö†Ô∏è Contraintes et Limitations

### Ressources N√©cessaires
- **GPU** : N√©cessaire pour l'entra√Ænement Prithvi (16GB+ VRAM recommand√©)
- **Espace disque** : ~50GB pour le mod√®le et les donn√©es
- **Temps** : 8-12h pour l'entra√Ænement complet

### Alternatives si Pas de GPU
1. **Utiliser Google Colab Pro** (GPU gratuit limit√©)
2. **Utiliser Kaggle** (GPU gratuit 30h/semaine)
3. **Se concentrer sur le baseline** uniquement
4. **Utiliser un mod√®le plus petit** (Prithvi-100M au lieu de 2.3B)

### Strat√©gie de Fallback
Si l'entra√Ænement n'est pas possible :
- ‚úÖ Pr√©senter le baseline model (d√©j√† impl√©ment√©)
- ‚úÖ Expliquer l'architecture Prithvi (code pr√™t)
- ‚úÖ Utiliser des pr√©dictions mock√©es mais r√©alistes
- ‚úÖ Mettre l'accent sur la m√©thodologie et l'innovation

---

## üìù Checklist Finale

### Avant Soumission
- [ ] Vraies donn√©es charg√©es et valid√©es
- [ ] Baseline model ex√©cut√© avec vraies m√©triques
- [ ] Mod√®le Prithvi entra√Æn√© (ou explication si impossible)
- [ ] API d√©ploy√©e et fonctionnelle
- [ ] Frontend connect√© aux vraies donn√©es
- [ ] M√©triques r√©elles dans `results/all_metrics.json`
- [ ] Rapport final avec vraies valeurs
- [ ] Vid√©o d√©mo avec vraies donn√©es
- [ ] Slides finalis√©es

---

## üöÄ Commandes Rapides

### Tester l'ETL avec vraies donn√©es
```bash
cd GenHack4-Hackathon-Vertex
python3 -c "
from src.etl import ETLPipeline
from pathlib import Path

etl = ETLPipeline(
    era5_dir=Path('../datasets/main/derived-era5-land-daily-statistics'),
    sentinel2_dir=Path('../datasets/main/sentinel2_ndvi'),
    ecad_zip=Path('../datasets/ECA_blend_tx.zip'),
    gadm_gpkg=Path('../datasets/main/gadm_410_europe.gpkg'),
    output_dir=Path('./data/processed'),
    city_name='Paris',
    country_code='FRA'
)
etl.run_etl()
"
```

### Lancer le baseline
```bash
cd GenHack4-Hackathon-Vertex
python3 scripts/generate_baseline_metrics.py
```

### Tester l'API localement
```bash
cd GenHack4-Hackathon-Vertex
python3 src/api_simple.py
# Dans un autre terminal
curl http://localhost:8000/health
```

---

**Derni√®re mise √† jour** : 18 D√©cembre 2025

