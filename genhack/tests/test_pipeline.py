#!/usr/bin/env python3
"""
Quick test script to verify the pipeline works end-to-end
Uses a small subset of data for rapid validation
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from data_preparation import StationMetadataParser, StationTemperatureLoader
from modeling import ResidualLearningModel
import pandas as pd
import numpy as np


def test_station_parser():
    """Test station metadata parsing"""
    print("\n=== Test 1: Station Metadata Parser ===")
    
    parser = StationMetadataParser('../datasets/main/ECA_blend_tx/stations.txt')
    
    # Test DMS conversion
    test_cases = [
        ('+56:52:00', 56.8667),
        ('-12:30:00', -12.5000),
        ('+00:00:00', 0.0000)
    ]
    
    for dms, expected in test_cases:
        result = parser.dms_to_decimal(dms)
        assert abs(result - expected) < 0.01, f"DMS conversion failed: {dms} -> {result} (expected {expected})"
        print(f"  âœ“ {dms} -> {result:.4f}Â° (expected {expected:.4f}Â°)")
    
    # Parse all stations
    stations = parser.parse_stations()
    print(f"  âœ“ Parsed {len(stations)} stations")
    print(f"  âœ“ Countries: {stations['CN'].nunique()}")
    
    return True


def test_temperature_loader():
    """Test temperature data loading"""
    print("\n=== Test 2: Temperature Data Loader ===")
    
    parser = StationMetadataParser('../datasets/main/ECA_blend_tx/stations.txt')
    stations = parser.parse_stations()
    
    loader = StationTemperatureLoader(
        '../datasets/main/ECA_blend_tx',
        stations
    )
    
    # Load one station
    test_staid = stations.iloc[0]['STAID']
    df = loader.load_station_file(test_staid)
    
    print(f"  âœ“ Loaded station {test_staid}: {len(df)} raw observations")
    
    # Clean data
    df_clean = loader.clean_temperature_data(df)
    print(f"  âœ“ After cleaning: {len(df_clean)} valid observations")
    print(f"  âœ“ Temperature range: {df_clean['TX'].min():.1f}Â°C to {df_clean['TX'].max():.1f}Â°C")
    
    # Test country loading (small subset)
    print("\n  Testing country data loading (limited dates)...")
    country_data = loader.load_country_stations('SE', ('2023-07-01', '2023-07-31'))
    print(f"  âœ“ Loaded {len(country_data)} observations from {country_data['STAID'].nunique()} stations")
    
    return True


def test_model_features():
    """Test model feature preparation"""
    print("\n=== Test 3: Model Feature Preparation ===")
    
    # Create synthetic test data
    n_samples = 100
    test_data = pd.DataFrame({
        'DATE': pd.date_range('2023-07-01', periods=n_samples, freq='D'),
        'LAT': np.random.uniform(55, 65, n_samples),
        'LON': np.random.uniform(10, 20, n_samples),
        'ELEVATION': np.random.uniform(0, 500, n_samples),
        'NDVI': np.random.uniform(0.2, 0.8, n_samples),
        'ERA5_Temp': np.random.uniform(15, 30, n_samples),
        'Station_Temp': np.random.uniform(15, 30, n_samples),
        'Residual': np.random.uniform(-3, 3, n_samples),
        'STAID': np.random.randint(1, 10, n_samples),
        'DayOfYear': np.arange(1, n_samples + 1) % 365
    })
    
    model = ResidualLearningModel(model_type='random_forest')
    X, y = model.prepare_features(test_data)
    
    print(f"  âœ“ Feature matrix shape: {X.shape}")
    print(f"  âœ“ Target array shape: {y.shape}")
    print(f"  âœ“ Features: {model.feature_names}")
    
    # Test model training (quick)
    print("\n  Training test model (10 trees)...")
    model = ResidualLearningModel(model_type='random_forest', n_estimators=10, verbose=0)
    model.train(test_data)
    print("  âœ“ Model training successful")
    
    # Test prediction
    predictions = model.predict(test_data)
    print(f"  âœ“ Generated {len(predictions)} predictions")
    print(f"  âœ“ Prediction range: {predictions.min():.2f}Â°C to {predictions.max():.2f}Â°C")
    
    return True


def test_data_validation():
    """Test data validation and error handling"""
    print("\n=== Test 4: Data Validation ===")
    
    # Test with invalid data
    invalid_data = pd.DataFrame({
        'TX': [-9999, 250, 300, -100],  # Invalid values
        'Q_TX': [0, 1, 0, 9]  # Mixed quality
    })
    
    parser = StationMetadataParser('../datasets/main/ECA_blend_tx/stations.txt')
    stations = parser.parse_stations()
    loader = StationTemperatureLoader('../datasets/main/ECA_blend_tx', stations)
    
    cleaned = loader.clean_temperature_data(invalid_data)
    
    print(f"  âœ“ Input: {len(invalid_data)} rows")
    print(f"  âœ“ After cleaning: {len(cleaned)} rows")
    print("  âœ“ Invalid values correctly filtered")
    
    return True


def run_all_tests():
    """Run all tests"""
    print("=" * 70)
    print(" CLIMATE DOWNSCALING - PIPELINE VALIDATION")
    print("=" * 70)
    
    tests = [
        ("Station Parser", test_station_parser),
        ("Temperature Loader", test_temperature_loader),
        ("Model Features", test_model_features),
        ("Data Validation", test_data_validation),
    ]
    
    results = []
    
    for name, test_func in tests:
        try:
            success = test_func()
            results.append((name, success, None))
        except Exception as e:
            results.append((name, False, str(e)))
            print(f"\n  âœ— Test failed: {e}")
    
    # Summary
    print("\n" + "=" * 70)
    print(" TEST SUMMARY")
    print("=" * 70)
    
    passed = sum(1 for _, success, _ in results if success)
    total = len(results)
    
    for name, success, error in results:
        if success:
            print(f"  âœ“ {name}: PASSED")
        else:
            print(f"  âœ— {name}: FAILED")
            if error:
                print(f"    Error: {error}")
    
    print(f"\n  Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("\n  ğŸ‰ All tests passed! Pipeline is ready to use.")
        return 0
    else:
        print(f"\n  âš ï¸  {total - passed} test(s) failed. Please check the errors above.")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)
